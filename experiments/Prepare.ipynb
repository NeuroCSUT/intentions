{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"coop_navi_test_2.pkl\", \"rb\")\n",
    "data = pickle.load(fp)\n",
    "agent1 = pickle.load(fp)\n",
    "agent2 = pickle.load(fp)\n",
    "agent3 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes: 4001\n",
      "Something something: 1\n",
      "First episode length: 24\n",
      "Number of agents: 3\n",
      "Performance data items: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of episodes:\", len(data))\n",
    "print(\"Something something:\", len(data[0]))\n",
    "print(\"First episode length:\", len(data[0][0]))\n",
    "print(\"Number of agents:\", len(data[0][0][0]))\n",
    "print(\"Performance data items:\", len(data[0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode lengths:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Episode lengths:\")\n",
    "[len(data[i][0]) for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance data (reward, collisions, min_dists, occupied_landmarks):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-1.398971013032809, 1, 0.398971013032809, 1),\n",
       " (-1.2704639577251478, 1, 0.27046395772514775, 1),\n",
       " (-1.1844202393924324, 1, 0.18442023939243246, 3),\n",
       " (-1.3247311887996032, 1, 0.3247311887996031, 1),\n",
       " (-1.4137752011065765, 1, 0.4137752011065766, 1),\n",
       " (-1.1497638750999932, 1, 0.14976387509999325, 3),\n",
       " (-1.177113531619953, 1, 0.17711353161995308, 2),\n",
       " (-1.6040079017109763, 1, 0.6040079017109763, 1),\n",
       " (-1.324380115226227, 1, 0.32438011522622695, 1),\n",
       " (-1.1719803714668693, 1, 0.17198037146686918, 3),\n",
       " (-1.2853065925039449, 1, 0.28530659250394486, 2),\n",
       " (-1.2150797472690786, 1, 0.21507974726907858, 3),\n",
       " (-1.2132708770514253, 1, 0.21327087705142542, 2),\n",
       " (-1.2109654127199327, 1, 0.21096541271993266, 3),\n",
       " (-1.199468113693102, 1, 0.19946811369310202, 3)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Performance data (reward, collisions, min_dists, occupied_landmarks):\")\n",
    "[data[i][0][-1][0] for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps: 100025\n",
      "Number of datas per step 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of steps:\", len(agent1))\n",
    "print(\"Number of datas per step\", len(agent1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: [ 0.          0.          0.9448366   0.81041042 -0.54388864 -1.71701537\n",
      " -0.45176729 -1.62840284 -1.65661207 -0.5335673  -1.8086971  -1.52109112\n",
      " -1.46952064 -0.5171732   0.          0.          0.          0.        ]\n",
      "Action: [3.3950317e-05 3.7543112e-05 4.5126571e-06 2.2656102e-06 9.9992168e-01]\n",
      "Reward: -3.682998410517898\n",
      "Next state: [ 1.65152269e-05 -4.99959707e-01  9.44838248e-01  7.60414453e-01\n",
      " -5.43890295e-01 -1.66701940e+00 -4.51768942e-01 -1.57840687e+00\n",
      " -1.65661372e+00 -4.83571326e-01 -1.75869972e+00 -1.47109581e+00\n",
      " -1.51608864e+00 -4.70174631e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "Done: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"State:\", agent1[0][0])\n",
    "print(\"Action:\", agent1[0][1])\n",
    "print(\"Reward:\", agent1[0][2])\n",
    "print(\"Next state:\", agent1[0][3])\n",
    "print(\"Done:\", agent1[0][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shapes: (4001, 25, 18) (4001, 25, 18) (4001, 25, 18)\n"
     ]
    }
   ],
   "source": [
    "states1 = np.array([agent1[i][0] for i in range(len(agent1))]).reshape((-1, 25, len(agent1[0][0])))\n",
    "states2 = np.array([agent2[i][0] for i in range(len(agent2))]).reshape((-1, 25, len(agent2[0][0])))\n",
    "states3 = np.array([agent3[i][0] for i in range(len(agent3))]).reshape((-1, 25, len(agent3[0][0])))\n",
    "print(\"State shapes:\", states1.shape, states2.shape, states3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action shapes: (4001, 25, 5) (4001, 25, 5) (4001, 25, 5)\n"
     ]
    }
   ],
   "source": [
    "actions1 = np.array([agent1[i][1] for i in range(len(agent1))]).reshape((-1, 25, len(agent1[0][1])))\n",
    "actions2 = np.array([agent2[i][1] for i in range(len(agent2))]).reshape((-1, 25, len(agent2[0][1])))\n",
    "actions3 = np.array([agent3[i][1] for i in range(len(agent3))]).reshape((-1, 25, len(agent3[0][1])))\n",
    "print(\"Action shapes:\", actions1.shape, actions2.shape, actions3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward shapes: (4001, 25) (4001, 25) (4001, 25)\n"
     ]
    }
   ],
   "source": [
    "rewards1 = np.array([agent1[i][2] for i in range(len(agent1))]).reshape((-1, 25))\n",
    "rewards2 = np.array([agent2[i][2] for i in range(len(agent2))]).reshape((-1, 25))\n",
    "rewards3 = np.array([agent3[i][2] for i in range(len(agent3))]).reshape((-1, 25))\n",
    "print(\"Reward shapes:\", rewards1.shape, rewards2.shape, rewards3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collisions shapes: (4001,) (4001,) (4001,)\n"
     ]
    }
   ],
   "source": [
    "collisions1 = np.array([data[i][0][-1][0][1] for i in range(len(data))])\n",
    "collisions2 = np.array([data[i][0][-1][1][1] for i in range(len(data))])\n",
    "collisions3 = np.array([data[i][0][-1][2][1] for i in range(len(data))])\n",
    "print(\"Collisions shapes:\", collisions1.shape, collisions2.shape, collisions3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  53,  256,  665,  868, 1114, 1143, 1213, 1516, 1666, 2075, 2258,\n",
       "        2486, 2614, 2751, 2771, 3489, 3528, 3673, 3687, 3713]),)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(collisions1 != collisions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  53,  682, 1122, 1304, 1516, 1638, 2312, 2477, 2634, 2664, 2765,\n",
       "        2834, 3235, 3238, 3528, 3713, 3903, 3967]),)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(collisions2 != collisions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 256,  665,  682,  868, 1114, 1122, 1143, 1213, 1304, 1638, 1666,\n",
       "        2075, 2258, 2312, 2477, 2486, 2614, 2634, 2664, 2751, 2765, 2771,\n",
       "        2834, 3235, 3238, 3489, 3673, 3687, 3903, 3967]),)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(collisions1 != collisions3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - collisions are tracked separately for each agent. Collisions happen in pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert occupied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupied shape: (4001,) (4001,) (4001,)\n"
     ]
    }
   ],
   "source": [
    "occupied1 = np.array([data[i][0][-1][0][3] for i in range(len(data))])\n",
    "occupied2 = np.array([data[i][0][-1][1][3] for i in range(len(data))])\n",
    "occupied3 = np.array([data[i][0][-1][2][3] for i in range(len(data))])\n",
    "print(\"Occupied shape:\", occupied1.shape, occupied2.shape, occupied3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug occupied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(occupied1 != occupied2))\n",
    "print(np.sum(occupied2 != occupied3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - occupied is common over all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes, where:\n",
      "- all landmarks are covered 1213\n",
      "- at least 2 landmarks covered 2824\n",
      "- at least 1 landmark covered 3817\n",
      "- zero landmarks covered 184\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of episodes, where:\")\n",
    "print(\"- all landmarks are covered\", np.sum(occupied1 == 3))\n",
    "print(\"- at least 2 landmarks covered\", np.sum(occupied1 >= 2))\n",
    "print(\"- at least 1 landmark covered\", np.sum(occupied1 >= 1))\n",
    "print(\"- zero landmarks covered\", np.sum(occupied1 == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert landmarks occupied by agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks shapes: (4001, 3) (4001, 3) (4001, 3)\n"
     ]
    }
   ],
   "source": [
    "# calculate distance of each agent from each landmark\n",
    "landmarks1 = np.sqrt(np.sum(states1[:,-1,4:10].reshape((states1.shape[0], 3, 2))**2, axis=-1))\n",
    "landmarks2 = np.sqrt(np.sum(states2[:,-1,4:10].reshape((states2.shape[0], 3, 2))**2, axis=-1))\n",
    "landmarks3 = np.sqrt(np.sum(states3[:,-1,4:10].reshape((states3.shape[0], 3, 2))**2, axis=-1))\n",
    "print(\"Landmarks shapes:\", landmarks1.shape, landmarks2.shape, landmarks3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug landmark occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent1 covers some landmark: 2910\n",
      "Agent2 covers some landmark: 1796\n",
      "Agent3 covers some landmark: 3118\n"
     ]
    }
   ],
   "source": [
    "print(\"Agent1 covers some landmark:\", np.sum(np.sum(landmarks1 < 0.1, axis=-1) > 0))\n",
    "print(\"Agent2 covers some landmark:\", np.sum(np.sum(landmarks2 < 0.1, axis=-1) > 0))\n",
    "print(\"Agent3 covers some landmark:\", np.sum(np.sum(landmarks3 < 0.1, axis=-1) > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious why agent2 performs so bad... Maybe because it's in the middle? With random positioning that shouldn't be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent1 covers more than one landmark: 4\n",
      "Agent2 covers more than one landmark: 5\n",
      "Agent3 covers more than one landmark: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Agent1 covers more than one landmark:\", np.sum(np.sum(landmarks1 < 0.1, axis=-1) > 1))\n",
    "print(\"Agent2 covers more than one landmark:\", np.sum(np.sum(landmarks2 < 0.1, axis=-1) > 1))\n",
    "print(\"Agent3 covers more than one landmark:\", np.sum(np.sum(landmarks3 < 0.1, axis=-1) > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupied from landmarks: 1213\n",
      "Occupied from perf data: 1213\n",
      "All occupations match: True\n"
     ]
    }
   ],
   "source": [
    "occupied = np.logical_or(np.logical_or(landmarks1 < 0.1, landmarks2 < 0.1), landmarks3 < 0.1)\n",
    "all_occupied = np.all(occupied, axis=-1)\n",
    "print(\"Occupied from landmarks:\", np.sum(all_occupied))\n",
    "print(\"Occupied from perf data:\", np.sum(occupied1 == 3))\n",
    "print(\"All occupations match:\", np.all(all_occupied == (occupied1 == 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our landmark data matches the performance data. Can use landmark data further on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shapes: (4001, 3) (4001, 3) (4001, 3)\n"
     ]
    }
   ],
   "source": [
    "y1 = landmarks1 < 0.1\n",
    "y2 = landmarks2 < 0.1\n",
    "y3 = landmarks3 < 0.1\n",
    "print(\"Target shapes:\", y1.shape, y2.shape, y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent1 covered counts: [1091 2906    4    0]\n",
      "Agent2 covered counts: [2205 1791    5    0]\n",
      "Agent3 covered counts: [ 883 3097   21    0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Agent1 covered counts:\", np.histogram(np.sum(y1, axis=-1), [0, 1, 2, 3, 4])[0])\n",
    "print(\"Agent2 covered counts:\", np.histogram(np.sum(y2, axis=-1), [0, 1, 2, 3, 4])[0])\n",
    "print(\"Agent3 covered counts:\", np.histogram(np.sum(y3, axis=-1), [0, 1, 2, 3, 4])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import parse_args, make_env, get_trainers\n",
    "import maddpg.common.tf_util as U\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using good policy maddpg and adv policy maddpg\n",
      "Loading previous state...\n",
      "INFO:tensorflow:Restoring parameters from coop_navi_2/policy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.saver.Saver at 0x7fb32393bf60>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arglist = parse_args(['--benchmark', '--deterministic'])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.InteractiveSession().as_default()\n",
    "\n",
    "# Create environment\n",
    "env = make_env('simple_spread', arglist, arglist.benchmark)\n",
    "# Create agent trainers\n",
    "obs_shape_n = [env.observation_space[i].shape for i in range(env.n)]\n",
    "num_adversaries = min(env.n, arglist.num_adversaries)\n",
    "trainers = get_trainers(env, num_adversaries, obs_shape_n, arglist)\n",
    "print('Using good policy {} and adv policy {}'.format(arglist.good_policy, arglist.adv_policy))\n",
    "\n",
    "# Initialize\n",
    "U.initialize()\n",
    "\n",
    "print('Loading previous state...')\n",
    "U.load_state('coop_navi_2/policy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted actions match saved actions: True\n"
     ]
    }
   ],
   "source": [
    "actions = trainers[0].act(states1[0])\n",
    "print(\"Predicted actions match saved actions:\", np.allclose(actions1[0], actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent1 hidden state shapes: (4001, 25, 64) (4001, 25, 64)\n",
      "Agent2 hidden state shapes: (4001, 25, 64) (4001, 25, 64)\n",
      "Agent3 hidden state shapes: (4001, 25, 64) (4001, 25, 64)\n"
     ]
    }
   ],
   "source": [
    "h1_values = trainers[0].p_debug['h1_values']\n",
    "h2_values = trainers[0].p_debug['h2_values']\n",
    "\n",
    "X1_h1 = np.array([h1_values(states1[i]) for i in range(states1.shape[0])])\n",
    "X1_h2 = np.array([h2_values(states1[i]) for i in range(states1.shape[0])])\n",
    "\n",
    "print(\"Agent1 hidden state shapes:\", X1_h1.shape, X1_h2.shape)\n",
    "\n",
    "h1_values = trainers[1].p_debug['h1_values']\n",
    "h2_values = trainers[1].p_debug['h2_values']\n",
    "\n",
    "X2_h1 = np.array([h1_values(states2[i]) for i in range(states2.shape[0])])\n",
    "X2_h2 = np.array([h2_values(states2[i]) for i in range(states2.shape[0])])\n",
    "\n",
    "print(\"Agent2 hidden state shapes:\", X1_h1.shape, X1_h2.shape)\n",
    "\n",
    "h1_values = trainers[2].p_debug['h1_values']\n",
    "h2_values = trainers[2].p_debug['h2_values']\n",
    "\n",
    "X3_h1 = np.array([h1_values(states3[i]) for i in range(states3.shape[0])])\n",
    "X3_h2 = np.array([h2_values(states3[i]) for i in range(states3.shape[0])])\n",
    "\n",
    "print(\"Agent3 hidden state shapes:\", X1_h1.shape, X1_h2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"data.npz\",\n",
    "    X1_obs=states1, \n",
    "    X1_h1=X1_h1, \n",
    "    X1_h2=X1_h2,\n",
    "    X1_act=actions1,\n",
    "    X2_obs=states2, \n",
    "    X2_h1=X2_h1, \n",
    "    X2_h2=X2_h2,\n",
    "    X2_act=actions2,\n",
    "    X3_obs=states3, \n",
    "    X3_h1=X3_h1, \n",
    "    X3_h2=X3_h2,\n",
    "    X3_act=actions3,\n",
    "    y1=y1,\n",
    "    y2=y2,\n",
    "    y3=y3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
